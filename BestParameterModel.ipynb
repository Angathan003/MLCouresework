{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GSgKl28LV71Y"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -o -q bank.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")"
      ],
      "metadata": {
        "id": "_8IqJz5oWUw7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import imblearn for SMOTE\n",
        "!pip install -q imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "6cq5WxXeWcce"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and Keras for Neural Network\n",
        "!pip install -q tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# For handling warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "FqkA5i5PWh6n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Preprocess the Data\n",
        "\n",
        "# Read the bank-full.csv\n",
        "data = pd.read_csv(\"bank-full.csv\", sep=';')\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Display dataset information\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Display class distribution before preprocessing\n",
        "print(\"\\nClass Distribution Before Preprocessing:\")\n",
        "print(data['y'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rRK_NvwWl92",
        "outputId": "e748e8b5-4a6d-4ea2-ce40-031dad93157e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   age           job  marital  education default  balance housing loan  \\\n",
            "0   58    management  married   tertiary      no     2143     yes   no   \n",
            "1   44    technician   single  secondary      no       29     yes   no   \n",
            "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
            "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
            "4   33       unknown   single    unknown      no        1      no   no   \n",
            "\n",
            "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
            "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
            "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
            "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
            "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
            "4  unknown    5   may       198         1     -1         0  unknown  no  \n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45211 entries, 0 to 45210\n",
            "Data columns (total 17 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        45211 non-null  int64 \n",
            " 1   job        45211 non-null  object\n",
            " 2   marital    45211 non-null  object\n",
            " 3   education  45211 non-null  object\n",
            " 4   default    45211 non-null  object\n",
            " 5   balance    45211 non-null  int64 \n",
            " 6   housing    45211 non-null  object\n",
            " 7   loan       45211 non-null  object\n",
            " 8   contact    45211 non-null  object\n",
            " 9   day        45211 non-null  int64 \n",
            " 10  month      45211 non-null  object\n",
            " 11  duration   45211 non-null  int64 \n",
            " 12  campaign   45211 non-null  int64 \n",
            " 13  pdays      45211 non-null  int64 \n",
            " 14  previous   45211 non-null  int64 \n",
            " 15  poutcome   45211 non-null  object\n",
            " 16  y          45211 non-null  object\n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 5.9+ MB\n",
            "None\n",
            "\n",
            "Class Distribution Before Preprocessing:\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'duration' to Avoid Data Leakage\n",
        "\n",
        "# In realistic scenarios, 'duration' is unknown at the time of prediction.\n",
        "if 'duration' in data.columns:\n",
        "    data = data.drop(['duration'], axis=1)\n",
        "    print(\"\\n'Duration' column dropped to prevent data leakage.\")\n",
        "else:\n",
        "    print(\"\\n'Duration' column not found in the dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1jE1jlyWxRu",
        "outputId": "9d8849ec-6e71-4d84-e4a8-2280ea680aad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'Duration' column dropped to prevent data leakage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle Missing Values\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# If missing values exist, handle them\n",
        "if missing_values.sum() > 0:\n",
        "    # For numerical columns, fill with median\n",
        "    numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
        "    data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
        "\n",
        "    # For categorical columns, fill with mode\n",
        "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "    data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])\n",
        "    print(\"\\nMissing values have been handled.\")\n",
        "else:\n",
        "    print(\"\\nNo missing values found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOCCsGMhW7dq",
        "outputId": "8a6c7814-8c64-4016-9783-9b383332badb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values in Each Column:\n",
            "age          0\n",
            "job          0\n",
            "marital      0\n",
            "education    0\n",
            "default      0\n",
            "balance      0\n",
            "housing      0\n",
            "loan         0\n",
            "contact      0\n",
            "day          0\n",
            "month        0\n",
            "campaign     0\n",
            "pdays        0\n",
            "previous     0\n",
            "poutcome     0\n",
            "y            0\n",
            "dtype: int64\n",
            "\n",
            "No missing values found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier Detection and Handling for 'previous' Column\n",
        "# Detect and cap outliers in the 'previous' column using the IQR method\n",
        "if 'previous' in data.columns:\n",
        "    Q1 = data['previous'].quantile(0.25)\n",
        "    Q3 = data['previous'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Capping the outliers\n",
        "    data['previous'] = np.where(data['previous'] < lower_bound, lower_bound, data['previous'])\n",
        "    data['previous'] = np.where(data['previous'] > upper_bound, upper_bound, data['previous'])\n",
        "    print(\"\\nOutliers in 'previous' column have been capped.\")\n",
        "else:\n",
        "    print(\"\\n'previous' column not found in the dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4bNJj1bXMQ4",
        "outputId": "1f31bafe-611a-4c90-bba2-9d35b651ab78"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Outliers in 'previous' column have been capped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle 'pdays' Column\n",
        "# 'pdays' - number of days that passed after the client was last contacted from a previous campaign\n",
        "# -1 indicates that the client was not previously contacted\n",
        "\n",
        "# Create a new binary feature indicating if the client was previously contacted\n",
        "data['previously_contacted'] = np.where(data['pdays'] == -1, 0, 1)\n",
        "\n",
        "# Replace -1 in 'pdays' with 0 for scaling purposes\n",
        "data['pdays'] = data['pdays'].replace(-1, 0)\n",
        "\n",
        "print(\"\\n'previously_contacted' feature created and 'pdays' values adjusted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJN0Y4dSXW6W",
        "outputId": "27e866ae-bc1d-49d0-bce3-ebfd88f55c10"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'previously_contacted' feature created and 'pdays' values adjusted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering on Numeric Columns\n",
        "# Define numeric columns\n",
        "numeric_cols = ['age', 'pdays', 'previous', 'balance', 'campaign', 'day']\n",
        "\n",
        "# Create new ratio-based features, handling potential division by zero\n",
        "data['age_balance_ratio'] = data['age'] / (data['balance'] + 1e-6)  # Adding a small constant to avoid division by zero\n",
        "data['campaign_balance_ratio'] = data['campaign'] / (data['balance'] + 1e-6)\n",
        "data['previous_campaign_ratio'] = data['previous'] / (data['campaign'] + 1e-6)\n",
        "\n",
        "print(\"\\nFeature engineering on numeric columns completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsHu2PMfXiB9",
        "outputId": "d5af60a0-cba1-485e-f86e-3cc36d2f73ae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature engineering on numeric columns completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Categorical Variables\n",
        "# Identify categorical columns (excluding the target variable 'y')\n",
        "categorical_cols = data.drop('y', axis=1).select_dtypes(include=['object']).columns\n",
        "print(\"\\nCategorical Columns:\", categorical_cols.tolist())\n",
        "\n",
        "# One-Hot Encoding for categorical variables\n",
        "X = pd.get_dummies(data.drop('y', axis=1), columns=categorical_cols, drop_first=True)\n",
        "print(\"\\nShape of feature matrix after one-hot encoding:\", X.shape)\n",
        "\n",
        "# Convert target variable to binary\n",
        "y = data['y'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Display class distribution before SMOTE\n",
        "print(\"\\nClass Distribution Before SMOTE:\")\n",
        "print(y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvBfSIL7Xsey",
        "outputId": "09fb4d28-bff3-40d3-8094-a2c8db294288"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categorical Columns: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
            "\n",
            "Shape of feature matrix after one-hot encoding: (45211, 45)\n",
            "\n",
            "Class Distribution Before SMOTE:\n",
            "y\n",
            "0    39922\n",
            "1     5289\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE for Oversampling Before Scaling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nClass Distribution After SMOTE:\")\n",
        "print(pd.Series(y_resampled).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3p5b3cIX6kt",
        "outputId": "e98df78b-30b8-4edc-9f3d-996d903d9033"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution After SMOTE:\n",
            "y\n",
            "0    39922\n",
            "1    39922\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Only Numerical Features\n",
        "# Define all numeric columns including the newly created features\n",
        "scaled_numeric_cols = [\n",
        "    'age', 'pdays', 'previous', 'balance', 'campaign', 'day',\n",
        "    'age_balance_ratio', 'campaign_balance_ratio', 'previous_campaign_ratio'\n",
        "]\n",
        "\n",
        "# Check if all scaled_numeric_cols are in X_resampled\n",
        "missing_scaled_numeric = set(scaled_numeric_cols) - set(X_resampled.columns)\n",
        "if missing_scaled_numeric:\n",
        "    print(f\"\\nWarning: The following numerical columns are missing and will be skipped for scaling: {missing_scaled_numeric}\")\n",
        "    scaled_numeric_cols = list(set(scaled_numeric_cols) - missing_scaled_numeric)\n",
        "else:\n",
        "    print(\"\\nAll numeric columns identified for scaling.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lZm_zytYE5P",
        "outputId": "30e9d61a-c207-4213-8e14-b282f78f67c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All numeric columns identified for scaling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract numerical columns for scaling\n",
        "X_numerical = X_resampled[scaled_numeric_cols]\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the numerical features\n",
        "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
        "\n",
        "# Create a DataFrame for scaled numerical features\n",
        "X_numerical_scaled_df = pd.DataFrame(\n",
        "    X_numerical_scaled,\n",
        "    columns=scaled_numeric_cols,\n",
        "    index=X_resampled.index\n",
        ")\n",
        "\n",
        "# Drop original numerical columns from X_resampled\n",
        "X_resampled = X_resampled.drop(columns=scaled_numeric_cols)\n",
        "\n",
        "# Concatenate scaled numerical features with the rest of the data\n",
        "X_resampled = pd.concat([X_resampled, X_numerical_scaled_df], axis=1)\n",
        "\n",
        "print(\"\\nShape of feature matrix after scaling numerical features:\", X_resampled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ntOClAeYSzA",
        "outputId": "0044bf84-d3ff-4a2d-a52a-b3456a625511"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of feature matrix after scaling numerical features: (79844, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Data into Train and Test Sets\n",
        "X_final = X_resampled\n",
        "y_final = y_resampled\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_final, y_final,\n",
        "    test_size=0.2,  # 20% for testing\n",
        "    random_state=42,\n",
        "    stratify=y_final\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Set Class Distribution:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"\\nTesting Set Class Distribution:\")\n",
        "print(pd.Series(y_test).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNIH-6FBYb17",
        "outputId": "7b7ee332-886f-4232-d618-01024b2dbd5e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Set Class Distribution:\n",
            "y\n",
            "1    31938\n",
            "0    31937\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing Set Class Distribution:\n",
            "y\n",
            "0    7985\n",
            "1    7984\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning for Random Forest using RandomizedSearchCV\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 6],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of parameter settings that are sampled\n",
        "    scoring='roc_auc',\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "print(\"\\nStarting RandomizedSearchCV for Hyperparameter Tuning...\")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best parameters\n",
        "best_params_rf = random_search.best_params_\n",
        "print(\"\\nBest Parameters Found for Random Forest:\")\n",
        "print(best_params_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8en0obFzYlOX",
        "outputId": "61ad32e6-17f2-40db-beba-a8c97955e459"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RandomizedSearchCV for Hyperparameter Tuning...\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "\n",
            "Best Parameters Found for Random Forest:\n",
            "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
          ]
        }
      ]
    }
  ]
}